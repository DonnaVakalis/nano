{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Model Diagnostics.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonnaVakalis/nano/blob/master/Model_Diagnostics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_WSsRI-koEJ",
        "colab_type": "text"
      },
      "source": [
        "### Model Diagnostics in Python\n",
        "\n",
        "In this notebook, you will be trying out some of the model diagnostics you saw from Sebastian, but in your case there will only be two cases - either admitted or not admitted.\n",
        "\n",
        "First let's read in the necessary libraries and the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBodC8GJkoEL",
        "colab_type": "code",
        "colab": {},
        "outputId": "56d5df7d-65bc-4469-d785-f5520bf63945"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(42)\n",
        "\n",
        "df = pd.read_csv('./admissions.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>admit</th>\n",
              "      <th>gre</th>\n",
              "      <th>gpa</th>\n",
              "      <th>prestige</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>380</td>\n",
              "      <td>3.61</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>660</td>\n",
              "      <td>3.67</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>800</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>640</td>\n",
              "      <td>3.19</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>520</td>\n",
              "      <td>2.93</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   admit  gre   gpa  prestige\n",
              "0      0  380  3.61         3\n",
              "1      1  660  3.67         3\n",
              "2      1  800  4.00         1\n",
              "3      1  640  3.19         4\n",
              "4      0  520  2.93         4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtJL3w8FkoEU",
        "colab_type": "text"
      },
      "source": [
        "`1.` Change prestige to dummy variable columns that are added to `df`.  Then divide your data into training and test data.  Create your test set as 20% of the data, and use a random state of 0.  Your response should be the `admit` column.  [Here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) are the docs, which can also find with a quick google search if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAcyP0FXkoEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[['1','2','3','4']] = pd.get_dummies(df['prestige'])\n",
        "df.head()\n",
        "\n",
        "y = df['admit']\n",
        "X = df[['gre','gpa','1','2','3']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZdX0mM5koEZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "4069b18b-1835-40f4-8480-1631b81dc932"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(397, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdC_iCiIkoEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Byi86863koEh",
        "colab_type": "text"
      },
      "source": [
        "`2.` Now use [sklearn's Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to fit a logistic model using `gre`, `gpa`, and 3 of your `prestige` dummy variables.  For now, fit the logistic regression model without changing any of the hyperparameters.  \n",
        "\n",
        "The usual steps are:\n",
        "* Instantiate\n",
        "* Fit (on train)\n",
        "* Predict (on test)\n",
        "* Score (compare predict to test)\n",
        "\n",
        "As a first score, obtain the [confusion matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).  Then answer the first question below about how well your model performed on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64G_N5eJkoEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#instantiate\n",
        "log_mod = LogisticRegression()\n",
        "\n",
        "# fit on training data\n",
        "log_mod.fit(X_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_preds = log_mod.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ9wX6ROkoEn",
        "colab_type": "code",
        "colab": {},
        "outputId": "b6f7b905-2db8-4541-de11-80e796bd7095"
      },
      "source": [
        "# score using test set using confusion matrix\n",
        "confusion_matrix(y_test,y_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[56,  0],\n",
              "       [22,  2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO-j4EaTkoEp",
        "colab_type": "text"
      },
      "source": [
        "`3.` Now, try out a few additional metrics: [precision](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html), [recall](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html), and [accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) are all popular metrics, which you saw with Sebastian.  You could compute these directly from the confusion matrix, but you can also use these built in functions in sklearn.\n",
        "\n",
        "Another very popular set of metrics are [ROC curves and AUC](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py).  These actually use the probability from the logistic regression models, and not just the label.  [This](http://blog.yhat.com/posts/roc-curves.html) is also a great resource for understanding ROC curves and AUC.\n",
        "\n",
        "Try out these metrics to answer the second quiz question below.  I also provided the ROC plot below.  The ideal case is for this to shoot all the way to the upper left hand corner.  Again, these are discussed in more detail in the Machine Learning Udacity program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2-hd-WbkoEq",
        "colab_type": "code",
        "colab": {},
        "outputId": "34896162-81ab-4969-a316-4ad5d112e429"
      },
      "source": [
        " print(precision_score(y_test,y_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3zzvIYbkoEt",
        "colab_type": "code",
        "colab": {},
        "outputId": "be16dae4-db45-43d6-a654-7c72165ca8d6"
      },
      "source": [
        "print(recall_score(y_test,y_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0833333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xNuzc4WkoEv",
        "colab_type": "code",
        "colab": {},
        "outputId": "4f3247a2-503c-47ab-fa6b-3c7604a4a08e"
      },
      "source": [
        "print(accuracy_score(y_test,y_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS_OspQgkoE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Unless you install the ggplot library in the workspace, you will \n",
        "### get an error when running this code!\n",
        "!pip install ggplot \n",
        "from ggplot import *\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "%matplotlib inline\n",
        "\n",
        "preds = log_mod.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(y_test, preds)\n",
        "\n",
        "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
        "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
        "    geom_line() +\\\n",
        "    geom_abline(linetype='dashed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aa4LN3FkoE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}